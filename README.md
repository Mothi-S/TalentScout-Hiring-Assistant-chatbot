# TalentScout Hiring Assistant ğŸ¤–

An interactive AI-powered Streamlit chatbot that simulates a mini technical recruiter. It gathers candidate details conversationally and generates personalized technical interview questions based on selected tech stacks (Python, React, MySQL, etc.). Powered by the quantized LLaMA 2 7B model and fully runs on CPU â€“ no GPU required!

---

## ğŸ“ Folder Structure

talentscout-hiring-assistant/
â”‚
â”œâ”€â”€ app.py # Streamlit chatbot app
â”œâ”€â”€ llm_loader.py # Loads LLaMA 2 model and handles inference
â”œâ”€â”€ prompt_generator.py # Builds custom prompts based on user input
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ .gitignore # Git ignore rules
â””â”€â”€ models/ # llama-2-7b-chat.ggmlv3.q8_0.bin [ğŸ’¾ Place quantized LLaMA 2 model file here ]

---

## ğŸš€ Features

- Conversational form for collecting user details
- Dynamic prompt creation based on selected tech stack
- CPU-based inference using quantized LLaMA 2 7B model
- Lightweight deployment using Streamlit
- Facebook-like chat styling using Streamlitâ€™s `chat_message`

---

## ğŸ”§ Installation Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Mothi-S/TalentScout-Hiring-Assistant-chatbot.git
cd TalentScout-Hiring-Assistant-chatbot

### 2. Set Up Virtual Environment

python -m venv venv
venv\Scripts\activate  # For Windows
# OR
source venv/bin/activate  # For macOS/Linux

### 3. Install Dependencies

pip install -r requirements.txt

### 4. Download and Add the LLaMA 2 Model

Download the quantized LLaMA 2 7B model file (llama-2-7b-chat.ggmlv3.q8_0.bin) from Hugging Face:

ğŸ“¥ Download from TheBloke's HuggingFace Repo

Create a folder named models/ in the project directory and place the .bin file inside it:

### 5. Run the Application

streamlit run app.py


